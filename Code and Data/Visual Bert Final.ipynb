{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13947,"status":"ok","timestamp":1692141412904,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"5i7JbvU1NC5j","outputId":"c6704eec-d3c4-4fbf-b21d-138fd9b1a91d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36613,"status":"ok","timestamp":1692145160768,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"gGwLUaUgSL9n","outputId":"71ae1657-d87a-478c-ff57-16dad5d779e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.6)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.0.3)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.7.1)\n","Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"]}],"source":["! pip install transformers\n","! pip install datasets\n","! pip install --upgrade tqdm\n","! pip install -U accelerate\n","! pip install pytorch-lightning"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":118,"status":"ok","timestamp":1692146506840,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"EN8lH9xXSvs5"},"outputs":[],"source":["# Standard libraries\n","import argparse\n","import logging\n","import os\n","import shutil\n","import time\n","from pathlib import Path\n","from string import punctuation\n","\n","# Third-party libraries\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import pytorch_lightning as pl\n","from pytorch_lightning.loggers import WandbLogger\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from sklearn.utils import class_weight\n","\n","# Transformers and related\n","import accelerate\n","import transformers\n","from transformers import (\n","    AdamW,\n","    BertTokenizer,\n","    VisualBertForPreTraining,\n","    VisualBertConfig,\n","    VisualBertModel,\n","    ViTFeatureExtractor,\n","    ViTModel,\n","    TrainingArguments,\n","    Trainer,\n","    AutoTokenizer,\n","    get_linear_schedule_with_warmup\n",")\n","from datasets import load_metric"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692146507330,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"6cjLM5dPzzaV"},"outputs":[],"source":["# Set the directory path for the model checkpoint\n","dirpath = '/content/drive/Mydrive/css688project2/model-checkpoint'\n","\n","# Check if the specified path exists and is a directory\n","if os.path.exists(dirpath) and os.path.isdir(dirpath):\n","    # If so, remove the directory and its contents\n","    shutil.rmtree(dirpath)"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":144,"status":"ok","timestamp":1692146508474,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"RUDydf6H0ddz"},"outputs":[],"source":["#Link to the path of the data folder\n","path = \"/content/drive/MyDrive/cs688project2/data/\""]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":124,"status":"ok","timestamp":1692146509505,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"k7nWls_fSzMi"},"outputs":[],"source":["#Read the data file with all data and split into train and test\n","df = pd.read_csv(path + 'final_cleaned_with_all_tags.csv')\n","df_train = df[:8500]\n","df_val = df[8500:9540]"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692146510093,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"a_192_dTP5Sn","outputId":"176f5324-f8e5-4e46-feda-174a292675b2"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-53-3692c9de37e6>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['idx'] = df_train['id'].astype(str).str.zfill(5)\n","<ipython-input-53-3692c9de37e6>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_val['idx'] = df_val['id'].astype(str).str.zfill(5)\n"]}],"source":["# Convert the 'id' column to a string type and pad it with zeros to a width of 5 characters for the training dataframe\n","df_train['idx'] = df_train['id'].astype(str).str.zfill(5)\n","\n","# Convert the 'id' column to a string type and pad it with zeros to a width of 5 characters for the validation dataframe\n","df_val['idx'] = df_val['id'].astype(str).str.zfill(5)\n"]},{"cell_type":"markdown","metadata":{"id":"8_ieiNwrLUzt"},"source":["## Compute Class Weight"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692146510522,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"HjGXoyRtLXuY","outputId":"a67d7259-337e-41dd-ec8c-8bebbc9b7878"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.77540595 1.40775091]\n"]}],"source":["# Extract the \"label\" column from the training dataframe and convert it to a list.\n","y_train = df_train[\"label\"].values.tolist()\n","\n","# Compute class weights using the 'balanced' strategy. This is useful when dealing with imbalanced datasets.\n","# The 'balanced' mode uses the formula n_samples / (n_classes * np.bincount(y)) to compute weights.\n","# It adjusts weights inversely proportional to class frequencies in the input data.\n","class_weights = class_weight.compute_class_weight(\n","    class_weight='balanced',          # Mode for calculating weights\n","    classes=np.unique(y_train),       # Unique class labels in the training data\n","    y=y_train                         # Class labels for the entire training dataset\n",")\n","\n","# Print the computed class weights.\n","print(class_weights)\n"]},{"cell_type":"markdown","metadata":{"id":"EQ0oB82ISJHA"},"source":["## Load Visual Embedding features"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1553,"status":"ok","timestamp":1692146513371,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"NlJiS4aLQD1_","outputId":"82d55dc0-ea36-4522-b060-9086d6e1669f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n"]}],"source":["# Initialize the tokenizer using the pretrained 'bert-base-uncased' model\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Initialize the feature extractor for the Vision Transformer using the pretrained 'google/vit-base-patch16-224-in21k' model\n","feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n","\n","# Initialize the Vision Transformer model using the pretrained 'google/vit-base-patch16-224-in21k' and move it to the GPU ('cuda')\n","feature_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k').to('cuda')\n"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692146513372,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"4pIK2KYvSnh-"},"outputs":[],"source":["class HatefulMemesData(Dataset):\n","    def __init__(self, df, tokenizer, sequence_length, print_text=False):\n","        \"\"\"Constructor for the custom dataset.\n","\n","        Parameters:\n","        - df (DataFrame): DataFrame containing the dataset information.\n","        - tokenizer: Tokenizer object for text processing.\n","        - sequence_length (int): Maximum length of token sequences.\n","        - print_text (bool): If True, prints text during tokenization.\n","        \"\"\"\n","\n","        self.sequence_length = sequence_length\n","        self.tokenizer = tokenizer\n","        self.print_text = print_text\n","\n","        # Extract columns from the DataFrame\n","        texts = df[\"text\"].values.tolist()\n","        labels = df[\"label\"].values.tolist()\n","        images = df[\"img\"].values.tolist()\n","        ids = df[\"idx\"].values.tolist()\n","\n","        # Construct a list of dictionaries from the extracted columns\n","        self.dataset = []\n","        for i, inp in enumerate(texts):\n","            self.dataset.append({\"text\": inp, \"label\": labels[i], 'idx': ids[i], 'image': images[i]})\n","\n","    def __len__(self):\n","        \"\"\"Returns the number of items in the dataset.\"\"\"\n","        return len(self.dataset)\n","\n","    def tokenize_data(self, example):\n","        \"\"\"Tokenize data for both text and image information.\n","\n","        Parameters:\n","        - example (dict): A dictionary containing text, label, idx, and image data.\n","\n","        Returns:\n","        - dict: A dictionary containing tokenized information.\n","        \"\"\"\n","\n","        idx = example['idx']\n","        idx = [idx] if isinstance(idx, str) else idx\n","\n","        # Tokenize the text data\n","        encoded_dict = tokenizer(example['text'], padding='max_length', max_length=self.sequence_length, truncation=True, return_tensors='pt')\n","        tokens = encoded_dict['input_ids']\n","        token_type_ids = encoded_dict['token_type_ids']\n","        attn_mask = encoded_dict['attention_mask']\n","        targets = torch.tensor(example['label']).type(torch.int64)\n","\n","        # Process the image data\n","        try:\n","            img = example['image']\n","            img = Image.open(os.path.join('hateful_memes', img))\n","            img = np.array(img)\n","            img = img[..., :3]\n","            inputs = feature_extractor(images=img, return_tensors=\"pt\")\n","            outputs = feature_model(**inputs.to('cuda'))\n","            visual_embeds = outputs.last_hidden_state\n","            visual_embeds = visual_embeds.cpu()\n","        except:\n","            visual_embeds = np.zeros(shape=(197, 768), dtype=float)\n","\n","        # Create masks for visual embeddings\n","        visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.int64)\n","        visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.int64)\n","\n","        # Construct the inputs dictionary for the model\n","        inputs = {\n","            \"input_ids\": tokens.squeeze(),\n","            \"attention_mask\": attn_mask.squeeze(),\n","            \"token_type_ids\": token_type_ids.squeeze(),\n","            \"visual_embeds\": visual_embeds.squeeze(),\n","            \"visual_token_type_ids\": visual_token_type_ids.squeeze(),\n","            \"visual_attention_mask\": visual_attention_mask.squeeze(),\n","            \"label\": targets.squeeze()\n","        }\n","\n","        return inputs\n","\n","    def __getitem__(self, index):\n","        \"\"\"Returns the tokenized data for a given index.\n","\n","        Parameters:\n","        - index (int): Index to retrieve data from.\n","\n","        Returns:\n","        - dict: Tokenized data for the given index.\n","        \"\"\"\n","\n","        inputs = self.tokenize_data(self.dataset[index])\n","\n","        # Print the tokenized data shapes and datatypes if print_text is True\n","        if self.print_text:\n","            for k in inputs.keys():\n","                print(k, inputs[k].shape, inputs[k].dtype)\n","\n","        return inputs"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692146513373,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"W5W2mYO_kLLf"},"outputs":[],"source":["#Create a dataset instance\n","dataset = HatefulMemesData(df_val, tokenizer, 50, True)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692146513850,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"i-_UouKgObfk","outputId":"8df651bb-23b3-4154-b345-f9673a361e4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.7754, 1.4078], device='cuda:0')\n"]}],"source":["\n","weights = [0.77540595, 1.40775091]\n","wt_tensor = torch.FloatTensor(weights).cuda()\n","print(wt_tensor)"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":134,"status":"ok","timestamp":1692146514318,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"rTSuZE5G3FNu"},"outputs":[],"source":["class VisualBERTClassifier(torch.nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        Initialize the necessary layers and configurations for the VisualBERT model.\n","        \"\"\"\n","        super(VisualBERTClassifier, self).__init__()\n","\n","        # Load the configuration for the VisualBert model with modified dropout rates\n","        configuration = VisualBertConfig.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre',\n","                                                hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\n","\n","        # Load the pretrained VisualBert model with the specified configuration\n","        self.visualbert = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre', config=configuration)\n","\n","        # Define a linear layer to transform visual embeddings\n","        self.embed_cls = nn.Linear(768, 1024)\n","\n","        # Define the number of output labels\n","        self.num_labels = 2\n","\n","        # Dropout layer for regularization\n","        self.dropout = nn.Dropout(0.3)\n","\n","        # Final classifier layer to map to the number of labels\n","        self.cls = nn.Linear(768, self.num_labels)\n","\n","        # Sample class weights\n","        self.weight = torch.FloatTensor([class_weights])\n","\n","        # Calculate normalized weights based on sample counts for classes\n","        nSamples = [5178, 2849]\n","        normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n","        # Loss function with weighted classes\n","        self.loss_fct = CrossEntropyLoss(weight=torch.FloatTensor(normedWeights))\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids, visual_embeds, visual_attention_mask,\n","                visual_token_type_ids, labels):\n","        \"\"\"\n","        In the forward pass, the model processes input data and returns the loss and logits.\n","        \"\"\"\n","        # Apply a linear transformation to the visual embeddings\n","        visual_embeds_cls = self.embed_cls(visual_embeds)\n","\n","        # Pass the input data through the VisualBert model\n","        outputs = self.visualbert(\n","                input_ids,\n","                attention_mask=attention_mask,\n","                token_type_ids=token_type_ids,\n","                visual_embeds=visual_embeds_cls,\n","                visual_attention_mask=visual_attention_mask,\n","                visual_token_type_ids=visual_token_type_ids,\n","            )\n","\n","        # Extract the pooled output (representative embedding) from the model's output\n","        pooled_output = outputs[1]\n","\n","        # Apply dropout for regularization\n","        pooled_output = self.dropout(pooled_output)\n","\n","        # Obtain logits by passing the pooled output through the classifier layer\n","        logits = self.cls(pooled_output)\n","\n","        # Reshape logits to match the expected shape\n","        reshaped_logits = logits.view(-1, self.num_labels)\n","\n","        # Calculate the cross-entropy loss between the predicted logits and true labels\n","        loss = self.loss_fct(reshaped_logits, labels.view(-1))\n","\n","        return loss, reshaped_logits"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":1527,"status":"ok","timestamp":1692146516329,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"Q6v7whCY5Qwy"},"outputs":[],"source":["# Initialize the VisualBERTClassifier model, and move it to the GPU (CUDA) for faster computation.\n","model = VisualBERTClassifier().to('cuda')\n"]},{"cell_type":"markdown","metadata":{"id":"f7tblaBP7Gb_"},"source":["## Using HuggingFace Trainer"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692146516329,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"UefymyHr7Jt_"},"outputs":[],"source":["# Define the metric name for evaluation. In this case, it's the Area Under the Receiver Operating Characteristic curve (AUROC).\n","metric_name = \"auroc\"\n","\n","# Initialize the TrainingArguments for the HuggingFace Trainer. This defines various training hyperparameters and settings.\n","args = TrainingArguments(\n","    output_dir=\"model-checkpoint\",  # Directory to save model checkpoints\n","    seed=42,  # Random seed for reproducibility\n","    evaluation_strategy=\"steps\",  # Evaluation and logging are done at regular steps instead of at the end of the epoch\n","    learning_rate=1e-5,  # Initial learning rate\n","    per_device_train_batch_size=24,  # Batch size for training\n","    per_device_eval_batch_size=24,  # Batch size for evaluation\n","    num_train_epochs=30,  # Total number of training epochs to perform\n","    weight_decay=0.05,  # Weight decay (L2 penalty) to apply\n","    load_best_model_at_end=True,  # Load the best model found during training (in terms of evaluation metric)\n","    metric_for_best_model=metric_name,  # Metric to use to identify the best model\n","    eval_steps=50,  # Evaluate the model every 50 steps\n","    save_steps=500,  # Save a model checkpoint every 500 steps\n","    fp16=False,  # Whether to use 16-bit (mixed) precision instead of 32-bit\n","    gradient_accumulation_steps=2  # Number of updates steps to accumulate gradients before performing an optimization step\n",")\n"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1692146516712,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"5-C8d6fw7Jwh"},"outputs":[],"source":["#Load acc metric\n","acc_metric = load_metric('accuracy')\n","\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"\n","    Compute accuracy and AUROC metrics based on model's predictions and true labels.\n","\n","    Parameters:\n","    - eval_pred: tuple containing the predicted logits and true labels.\n","\n","    Returns:\n","    - Dictionary containing the accuracy and AUROC scores.\n","    \"\"\"\n","\n","    # Split the eval_pred tuple into logits and true labels\n","    logits, labels = eval_pred\n","\n","    # Get the class with the highest probability as the predicted class\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Compute accuracy using the provided accuracy metric function\n","    acc = acc_metric.compute(predictions=predictions, references=labels)\n","\n","    # Compute the Area Under the Receiver Operating Characteristic curve (AUROC)\n","    auc_score = roc_auc_score(labels, predictions)\n","\n","    # Return the computed metrics in a dictionary\n","    return {\"accuracy\": acc['accuracy'], \"auroc\": auc_score}"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692146516713,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"qwSU1fNp70mt"},"outputs":[],"source":["# Initialize the HuggingFace Trainer. The Trainer is a utility class provided by the Transformers library\n","# to simplify the training and evaluation of models.\n","\n","trainer = Trainer(\n","    model,  # The instantiated model to be trained\n","    args,  # Training configuration (hyperparameters, evaluation strategy, etc.)\n","\n","    # Train dataset: 'HatefulMemesData' is a custom Dataset class. We initialize it with training data,\n","    # a tokenizer, and a specified sequence length for tokenization.\n","    train_dataset = HatefulMemesData(df_train, tokenizer=tokenizer, sequence_length=50),\n","\n","    # Evaluation dataset: Similar to the training dataset, but using validation data.\n","    eval_dataset =  HatefulMemesData(df_val, tokenizer=tokenizer, sequence_length=50),\n","\n","    tokenizer=tokenizer,  # The tokenizer used for encoding the text data\n","    compute_metrics=compute_metrics  # Function to compute custom evaluation metrics\n",")\n"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":789094,"status":"ok","timestamp":1692147306121,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"8c7lrnLe9lUO","outputId":"aaa4ab9f-62fa-44e7-9314-60238c62c621"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='177' max='177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [177/177 13:04, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Auroc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>No log</td>\n","      <td>0.726029</td>\n","      <td>0.490385</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>No log</td>\n","      <td>0.699542</td>\n","      <td>0.496154</td>\n","      <td>0.504994</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>No log</td>\n","      <td>0.707018</td>\n","      <td>0.491346</td>\n","      <td>0.499834</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=177, training_loss=0.6976944228350106, metrics={'train_runtime': 788.7444, 'train_samples_per_second': 10.777, 'train_steps_per_second': 0.224, 'total_flos': 0.0, 'train_loss': 0.6976944228350106, 'epoch': 1.0})"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["#Fine-tuning the model\n","trainer.train()"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":46523,"status":"ok","timestamp":1692147352628,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"NIzbDwJeY08R","outputId":"e4dc63d2-9e1c-4c38-93df-c28072c04347"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [44/44 00:44]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.7078133821487427,\n"," 'eval_accuracy': 0.49230769230769234,\n"," 'eval_auroc': 0.5007769145394007,\n"," 'eval_runtime': 46.5062,\n"," 'eval_samples_per_second': 22.363,\n"," 'eval_steps_per_second': 0.946,\n"," 'epoch': 1.0}"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["#Evaluating the model on test set\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":8039,"status":"ok","timestamp":1692147360650,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"0pm3hl5JY3k8"},"outputs":[],"source":["#Save the model for inference\n","trainer.save_model('/content/drive/MyDrive/cs688project2/data/VisualBERT_classification_model_without_tags')"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1692147360650,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"},"user_tz":240},"id":"41M50xYxQ5z8"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1Cbh14440-sGEwWIcUheZRP6OiOMBSSGx","timestamp":1691525585916}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
