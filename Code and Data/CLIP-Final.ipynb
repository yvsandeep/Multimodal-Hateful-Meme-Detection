{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eXuT2LgrLJ0EOWIkssV0eJzc6OQh-hsb","timestamp":1692147354526},{"file_id":"1ZqbLlmzsRS1_VVTdmkj_wQqHSC-x3CbX","timestamp":1691608929421}],"machine_shape":"hm","gpuType":"V100","mount_file_id":"10YtGvY-04kj34eYHUSyiOtuj5FrKnnMp","authorship_tag":"ABX9TyMAaIqBP3yIavGOEQ7AqM9b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e7ff675888ad4a7dad6d3c558aa35c91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d25a4c3bb89446991a245cece00dc29","IPY_MODEL_3dd4f893d94e4750b3f86cfb7bba104f","IPY_MODEL_51ceffb74a8d4d368a26e2508b183529"],"layout":"IPY_MODEL_1cdfc054b14b4dcc95e4c2f0247bca7e"}},"4d25a4c3bb89446991a245cece00dc29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fba1342720d452981cd8b2f058d9390","placeholder":"​","style":"IPY_MODEL_f67668cafed344139051cea8931bca22","value":"Downloading (…)lve/main/config.json: 100%"}},"3dd4f893d94e4750b3f86cfb7bba104f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_783148f971cd4df4812b2cdcb27d8c66","max":1080,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4877ed18980f422d8b49712ad4a0965a","value":1080}},"51ceffb74a8d4d368a26e2508b183529":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e132ce94cd949d298f18e0bcd250d05","placeholder":"​","style":"IPY_MODEL_e626a5b0065f497ba2ed712bc3db3fe9","value":" 1.08k/1.08k [00:00&lt;00:00, 56.8kB/s]"}},"1cdfc054b14b4dcc95e4c2f0247bca7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fba1342720d452981cd8b2f058d9390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f67668cafed344139051cea8931bca22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"783148f971cd4df4812b2cdcb27d8c66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4877ed18980f422d8b49712ad4a0965a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e132ce94cd949d298f18e0bcd250d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e626a5b0065f497ba2ed712bc3db3fe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fe0c7eb82f1431bbeedffc5f84800a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1743fdc522db4f6ea12791863cb902eb","IPY_MODEL_bf7f0c550a8648b5872fba9117b601fb","IPY_MODEL_57b2c4552b7343578ff3b687f8ec55c4"],"layout":"IPY_MODEL_7ea9e0d239154c8b81082eb7c98b897f"}},"1743fdc522db4f6ea12791863cb902eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47c9133bd03d4261907d5735ba1ea79a","placeholder":"​","style":"IPY_MODEL_c01a9af1e300468e967dffef2182d201","value":"Downloading pytorch_model.bin: 100%"}},"bf7f0c550a8648b5872fba9117b601fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca9aa5830bfa4c71b280d17b90254a27","max":437988463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_087dd8a3f1614b7a8f4dc2d934429713","value":437988463}},"57b2c4552b7343578ff3b687f8ec55c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ddfed45e5b8456891c456d4766c40cb","placeholder":"​","style":"IPY_MODEL_a00c0605d9f34aeca92972811fb94c82","value":" 438M/438M [00:07&lt;00:00, 62.3MB/s]"}},"7ea9e0d239154c8b81082eb7c98b897f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47c9133bd03d4261907d5735ba1ea79a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c01a9af1e300468e967dffef2182d201":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca9aa5830bfa4c71b280d17b90254a27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"087dd8a3f1614b7a8f4dc2d934429713":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ddfed45e5b8456891c456d4766c40cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a00c0605d9f34aeca92972811fb94c82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"673648f961534dd2ab5065e271f97c50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99e0c95baf6346578b8b93709980756e","IPY_MODEL_d3522c75db0d438c91e3fe2c7796c340","IPY_MODEL_ea5c525ec4b842899f029f416c9f0216"],"layout":"IPY_MODEL_71ace7a6401946468a2e14708357a89f"}},"99e0c95baf6346578b8b93709980756e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d9fdedbad1c48bdbf832f7464a36686","placeholder":"​","style":"IPY_MODEL_c274080ebac14e6598cc9efcc85c4d2a","value":"Downloading (…)okenizer_config.json: 100%"}},"d3522c75db0d438c91e3fe2c7796c340":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f95ef1fd92414c1bb40e38ddbf60a536","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba9c6b7adbe24a76af36f24732d1225a","value":40}},"ea5c525ec4b842899f029f416c9f0216":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41672651f1e146fa873f7ce90dfe39c0","placeholder":"​","style":"IPY_MODEL_23109c733dac495ba2c24659061f6f5c","value":" 40.0/40.0 [00:00&lt;00:00, 2.95kB/s]"}},"71ace7a6401946468a2e14708357a89f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d9fdedbad1c48bdbf832f7464a36686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c274080ebac14e6598cc9efcc85c4d2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f95ef1fd92414c1bb40e38ddbf60a536":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba9c6b7adbe24a76af36f24732d1225a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41672651f1e146fa873f7ce90dfe39c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23109c733dac495ba2c24659061f6f5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79660804e33444a7ba6a51f0296199f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a58d5ccee07544f198e4bb6f4239c119","IPY_MODEL_d832d63d6f574a6c98b4e7ff8b0c7d10","IPY_MODEL_98a8e43be19542bfac4d05aa1a69a5bb"],"layout":"IPY_MODEL_4a34fd44bd86490586921ec32d0c51b1"}},"a58d5ccee07544f198e4bb6f4239c119":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f84f9ad4f0846b79006a1b526d474ec","placeholder":"​","style":"IPY_MODEL_d3851d224c614ccdbbbf88a60b7c35e8","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"d832d63d6f574a6c98b4e7ff8b0c7d10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_983bf52376f24d78bdeda097b2c8ed68","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c103f77640fb4e99ac84e1395b210b12","value":231508}},"98a8e43be19542bfac4d05aa1a69a5bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7648af01ad0408a9a3473157a53658e","placeholder":"​","style":"IPY_MODEL_0d30947a8cbb409cb5c181f4887d4fd6","value":" 232k/232k [00:00&lt;00:00, 3.79MB/s]"}},"4a34fd44bd86490586921ec32d0c51b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f84f9ad4f0846b79006a1b526d474ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3851d224c614ccdbbbf88a60b7c35e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"983bf52376f24d78bdeda097b2c8ed68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c103f77640fb4e99ac84e1395b210b12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7648af01ad0408a9a3473157a53658e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d30947a8cbb409cb5c181f4887d4fd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b514666c161f4d96b3bb4f3d245c2ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a17bdf8b675d4fc0b108099c860a16da","IPY_MODEL_844da87cb5b54eb9a62b489486b3413c","IPY_MODEL_97f760561e324760ab27ea84e35c79b1"],"layout":"IPY_MODEL_53a60dba03584acfaab1b5d5de922fc1"}},"a17bdf8b675d4fc0b108099c860a16da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca2d4ccb27d942c7a012a804e6b02cdf","placeholder":"​","style":"IPY_MODEL_1d741267cc0347a6a81e812e1f0f17ee","value":"Downloading (…)cial_tokens_map.json: 100%"}},"844da87cb5b54eb9a62b489486b3413c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9014b842de742559986d05c50b4c931","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1918c1a4e0b2470da7813743e088522d","value":112}},"97f760561e324760ab27ea84e35c79b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5b165c9ce674ee8b7aed68cdf4eb369","placeholder":"​","style":"IPY_MODEL_53d2a2f17c0c40a085789ba4a9873f3e","value":" 112/112 [00:00&lt;00:00, 5.79kB/s]"}},"53a60dba03584acfaab1b5d5de922fc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca2d4ccb27d942c7a012a804e6b02cdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d741267cc0347a6a81e812e1f0f17ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9014b842de742559986d05c50b4c931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1918c1a4e0b2470da7813743e088522d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5b165c9ce674ee8b7aed68cdf4eb369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d2a2f17c0c40a085789ba4a9873f3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f85be8e2c4304d8cbbf41846e7404f4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca82ce8696c14c3d878c93f5c63a1c6d","IPY_MODEL_4cbd0175603346b9add2b86c21aad32f","IPY_MODEL_093e6fd0bfc64eaea1e50e1eded7a1c8"],"layout":"IPY_MODEL_dca6a3a1abbb46d1a36ead6691e35b3a"}},"ca82ce8696c14c3d878c93f5c63a1c6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_666e3f8e2dbd4eb182ed42a1c63e6e1f","placeholder":"​","style":"IPY_MODEL_f8fd3de03c2541a1a8cba39aef73738e","value":"100%"}},"4cbd0175603346b9add2b86c21aad32f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24602f546f4d4369a67f19ad96b19332","max":532,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b7b5b4ad89d437bb88c0b672d1e7979","value":532}},"093e6fd0bfc64eaea1e50e1eded7a1c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2f9e8ddbfe54a7f8decd27de8c9cc35","placeholder":"​","style":"IPY_MODEL_bf0f044922c84955a0476b6af3a454ae","value":" 532/532 [55:21&lt;00:00, 17.43s/it]"}},"dca6a3a1abbb46d1a36ead6691e35b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"666e3f8e2dbd4eb182ed42a1c63e6e1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8fd3de03c2541a1a8cba39aef73738e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24602f546f4d4369a67f19ad96b19332":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b7b5b4ad89d437bb88c0b672d1e7979":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2f9e8ddbfe54a7f8decd27de8c9cc35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0f044922c84955a0476b6af3a454ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e11fa0e616754fd7bf286b2e9135e9a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78bc4aaf7e2f4e16a5c2a828f86bd65c","IPY_MODEL_fb68a3c6e7364cf3bb5f80be2e442774","IPY_MODEL_b8e7078105774f379ea1351e2636195c"],"layout":"IPY_MODEL_ccf92f30de104ea9943e9ae7f549b517"}},"78bc4aaf7e2f4e16a5c2a828f86bd65c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f64c5d29eec4bf58e0cb6085f2ce7bd","placeholder":"​","style":"IPY_MODEL_483162e128ce4475a0f767f5b5ec19c4","value":" 28%"}},"fb68a3c6e7364cf3bb5f80be2e442774":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac455917be6a4045a2b08b8a4519e8b9","max":532,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fced1b06fd24654b7c4adab1f0ec9b5","value":151}},"b8e7078105774f379ea1351e2636195c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e428b47c5db1428a9e7e13b6f3820a1b","placeholder":"​","style":"IPY_MODEL_c81f914c711f4cafafc392838c14223d","value":" 151/532 [02:53&lt;04:48,  1.32it/s]"}},"ccf92f30de104ea9943e9ae7f549b517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f64c5d29eec4bf58e0cb6085f2ce7bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"483162e128ce4475a0f767f5b5ec19c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac455917be6a4045a2b08b8a4519e8b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fced1b06fd24654b7c4adab1f0ec9b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e428b47c5db1428a9e7e13b6f3820a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c81f914c711f4cafafc392838c14223d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install madgrad\n","!pip install transformers\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfkxxOIp6mp5","executionInfo":{"status":"ok","timestamp":1692148937000,"user_tz":240,"elapsed":35866,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}},"outputId":"0ce4c124-4ae1-4f1f-f893-5a4f68d34ad8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting madgrad\n","  Downloading madgrad-1.3.tar.gz (7.9 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: madgrad\n","  Building wheel for madgrad (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for madgrad: filename=madgrad-1.3-py3-none-any.whl size=11867 sha256=4a1e79542c7e78d24b866fd2c373bf94738256af9edeb2a060e37a2606573c6a\n","  Stored in directory: /root/.cache/pip/wheels/d9/a3/83/7ed1ddc517cd87cad4e3a4aec7f8ea1d5e83a5ff282e51490a\n","Successfully built madgrad\n","Installing collected packages: madgrad\n","Successfully installed madgrad-1.3\n","Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n","Installing collected packages: ftfy\n","Successfully installed ftfy-6.1.1\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-rwzv1udn\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-rwzv1udn\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369499 sha256=dc5752889c15c6b8446621fd3d284359165606578b57199458c515a5a016015a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-d9141mhi/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n","Successfully built clip\n","Installing collected packages: clip\n","Successfully installed clip-1.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cuiHtHKR6TtL","executionInfo":{"status":"ok","timestamp":1692148948383,"user_tz":240,"elapsed":11387,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"outputs":[],"source":["# Standard libraries\n","import os\n","import json\n","import random\n","import copy\n","from collections import Counter\n","\n","# Third-party libraries\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from PIL import Image\n","from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n","from matplotlib import pyplot as plt\n","from tqdm.notebook import tqdm\n","\n","# Torch specific\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from madgrad import MADGRAD\n","\n","# HuggingFace Transformers\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModel,\n","    AutoTokenizer,\n","    MMBTConfig,\n","    MMBTModel,\n","    MMBTForClassification,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","# Other specific modules/packages\n","import clip\n","import pickle\n"]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"LwgljkIk6USc","executionInfo":{"status":"ok","timestamp":1692148948384,"user_tz":240,"elapsed":6,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Load the CLIP model (\"RN50x4\" variant) and its preprocessing tools.\n","# The model is loaded onto the specified device (e.g., 'cuda' or 'cpu').\n","# The 'jit' argument determines whether the model should be loaded using PyTorch's Just-In-Time compiler; we've set it to False here.\n","clip_model, preprocess = clip.load(\"RN50x4\", device=device, jit=False)\n","\n","# Freeze all the weights of the CLIP model.\n","# This means the CLIP model will act as a feature extractor and won't be fine-tuned during training.\n","for p in clip_model.parameters():\n","    p.requires_grad = False\n","\n","# Set the number of image embeddings.\n","num_image_embeds = 4\n","\n","# Number of labels for classification. It's set to 1, possibly indicating a binary classification task.\n","num_labels = 1\n","\n","# Gradient accumulation steps indicate how often we'll update model weights.\n","# For instance, with a value of 20, we'll backpropagate the gradient but only update the weights every 20 batches.\n","gradient_accumulation_steps = 20\n","\n","# Directory where the data is stored.\n","data_dir = '/content/drive/MyDrive/cs688project2/data/'\n","\n","# Set the maximum sequence length for tokenizing text inputs.\n","max_seq_length = 80\n","\n","# Maximum gradient norm for gradient clipping. This helps in preventing extremely large gradient updates.\n","max_grad_norm = 0.5\n","\n","# Training and evaluation batch sizes.\n","train_batch_size = 16\n","eval_batch_size = 16\n","\n","# Define the size of the image encoder and the size of the image features.\n","image_encoder_size = 288\n","image_features_size = 640\n","\n","# Number of epochs the model will be trained for.\n","num_train_epochs = 5\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubhvSCLs6aZj","executionInfo":{"status":"ok","timestamp":1692148972977,"user_tz":240,"elapsed":24598,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}},"outputId":"33ffefd3-1f26-4bdf-9a33-90e076a47837"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 402M/402M [00:09<00:00, 46.7MiB/s]\n"]}]},{"cell_type":"code","source":["def slice_image(im, desired_size):\n","    \"\"\"\n","    Resize the input image and slice it into three parts (left, center, right or top, center, bottom).\n","\n","    Parameters:\n","    - im (PIL.Image): Input image.\n","    - desired_size (int): Desired size for slices.\n","\n","    Returns:\n","    - list of PIL.Image: List containing three sliced images.\n","    \"\"\"\n","\n","    # Compute the new size keeping the original aspect ratio\n","    old_size = im.size\n","    ratio = float(desired_size) / min(old_size)\n","    new_size = tuple([int(x * ratio) for x in old_size])\n","\n","    # Resize the image\n","    im = im.resize(new_size, Image.ANTIALIAS)\n","    ar = np.array(im)\n","\n","    images = []\n","\n","    # Determine the middle of the image and half of the desired size\n","    half = desired_size // 2\n","\n","    # Check if the image is landscape or portrait\n","    if ar.shape[0] < ar.shape[1]:  # Landscape\n","        middle = ar.shape[1] // 2\n","        images.append(Image.fromarray(ar[:, :desired_size]))\n","        images.append(Image.fromarray(ar[:, middle-half:middle+half]))\n","        images.append(Image.fromarray(ar[:, ar.shape[1]-desired_size:]))\n","    else:  # Portrait\n","        middle = ar.shape[0] // 2\n","        images.append(Image.fromarray(ar[:desired_size, :]))\n","        images.append(Image.fromarray(ar[middle-half:middle+half, :]))\n","        images.append(Image.fromarray(ar[ar.shape[0]-desired_size:, :]))\n","\n","    return images\n","\n","\n","def resize_pad_image(im, desired_size):\n","    \"\"\"\n","    Resize the input image and pad it to fit the desired size.\n","\n","    Parameters:\n","    - im (PIL.Image): Input image.\n","    - desired_size (int): Desired size for the output image.\n","\n","    Returns:\n","    - PIL.Image: Resized and padded image.\n","    \"\"\"\n","\n","    # Compute the new size keeping the original aspect ratio\n","    old_size = im.size\n","    ratio = float(desired_size) / max(old_size)\n","    new_size = tuple([int(x * ratio) for x in old_size])\n","\n","    # Resize the image\n","    im = im.resize(new_size, Image.ANTIALIAS)\n","\n","    # Create a new blank image and paste the resized image onto it\n","    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n","    new_im.paste(im, ((desired_size-new_size[0])//2, (desired_size-new_size[1])//2))\n","\n","    return new_im"],"metadata":{"id":"XMRvdJsC66U-","executionInfo":{"status":"ok","timestamp":1692148972978,"user_tz":240,"elapsed":13,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class ClipEncoderMulti(nn.Module):\n","    \"\"\"\n","    CLIP Encoder to encode multiple images into fixed-size embeddings.\n","\n","    Attributes:\n","    - model (nn.Module): CLIP model for image encoding.\n","    - num_embeds (int): Number of embeddings per input.\n","    - num_features (int): Size of the feature vector for each embedding.\n","    \"\"\"\n","\n","    def __init__(self, num_embeds, num_features=image_features_size):\n","        \"\"\"\n","        Initialize the ClipEncoderMulti class.\n","\n","        Parameters:\n","        - num_embeds (int): Number of embeddings per input.\n","        - num_features (int): Size of the feature vector for each embedding (default=image_features_size).\n","        \"\"\"\n","        super(ClipEncoderMulti, self).__init__()\n","        self.model = clip_model\n","        self.num_embeds = num_embeds\n","        self.num_features = num_features\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the ClipEncoderMulti model.\n","\n","        Parameters:\n","        - x (torch.Tensor): Input tensor of shape [batch_size, num_embeds, channels, height, width].\n","\n","        Returns:\n","        - torch.Tensor: Encoded images of shape [batch_size, num_embeds, num_features].\n","        \"\"\"\n","\n","        # Reshape input for encoding: merge the batch and num_embeds dimensions\n","        x_reshaped = x.view(-1, 3, 288, 288)\n","\n","        # Encode each image and get the embeddings\n","        out = self.model.encode_image(x_reshaped)\n","\n","        # Reshape output to separate batch size and num_embeds dimensions\n","        out = out.view(-1, self.num_embeds, self.num_features).float()\n","\n","        return out\n"],"metadata":{"id":"6CLrzXGOTNHr","executionInfo":{"status":"ok","timestamp":1692148972978,"user_tz":240,"elapsed":12,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class JsonlDataset(Dataset):\n","    \"\"\"\n","    Dataset class for loading data from a JSONL file format.\n","\n","    Attributes:\n","    - data (List[Dict]): Loaded data from the JSONL file.\n","    - data_dir (str): Directory path where the data file is located.\n","    - tokenizer (Tokenizer): Tokenizer for text preprocessing.\n","    - max_seq_length (int): Maximum sequence length for the text.\n","    - transforms (callable): Transformations to apply on images.\n","    \"\"\"\n","\n","    def __init__(self, data_path, tokenizer, transforms, max_seq_length):\n","        \"\"\"\n","        Initialize the JsonlDataset class.\n","\n","        Args:\n","        - data_path (str): Path to the JSONL data file.\n","        - tokenizer (Tokenizer): Tokenizer for text preprocessing.\n","        - transforms (callable): Transformations to apply on images.\n","        - max_seq_length (int): Maximum sequence length for the text.\n","        \"\"\"\n","        self.data = [json.loads(l) for l in open(data_path)]\n","        self.data_dir = os.path.dirname(data_path)\n","        self.tokenizer = tokenizer\n","        self.max_seq_length = max_seq_length\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        \"\"\"Returns the total number of data samples.\"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Fetches a single data sample.\n","\n","        Args:\n","        - index (int): Index of the data sample.\n","\n","        Returns:\n","        - Dict[Tensor]: A dictionary containing processed text and image data.\n","        \"\"\"\n","        # Process text\n","        sentence = torch.LongTensor(self.tokenizer.encode(self.data[index][\"text_with_tags\"], add_special_tokens=True))\n","        start_token, sentence, end_token = sentence[0], sentence[1:-1], sentence[-1]\n","        sentence = sentence[:self.max_seq_length]\n","        label = torch.FloatTensor([self.data[index][\"label\"]])\n","\n","        # Process image\n","        image = Image.open(os.path.join(self.data_dir, self.data[index][\"img\"])).convert(\"RGB\")\n","        sliced_images = slice_image(image, 288)\n","        sliced_images = [np.array(self.transforms(im)) for im in sliced_images]\n","        image = resize_pad_image(image, image_encoder_size)\n","        image = np.array(self.transforms(image))\n","        sliced_images = [image] + sliced_images\n","        sliced_images = torch.from_numpy(np.array(sliced_images)).to(device)\n","\n","        return {\n","            \"image_start_token\": start_token,\n","            \"image_end_token\": end_token,\n","            \"sentence\": sentence,\n","            \"image\": sliced_images,\n","            \"label\": label\n","        }\n","\n","    def get_label_frequencies(self):\n","        \"\"\"Returns a counter of label frequencies.\"\"\"\n","        return Counter(row[\"label\"] for row in self.data)\n","\n","    def get_labels(self):\n","        \"\"\"Returns a list of all labels in the dataset.\"\"\"\n","        return [row[\"label\"] for row in self.data]\n","\n","\n","def collate_fn(batch):\n","    \"\"\"\n","    Collation function to process a batch of data samples.\n","\n","    Args:\n","    - batch (List[Dict[Tensor]]): List of data samples.\n","\n","    Returns:\n","    - Tuple[Tensor]: Processed batch data.\n","    \"\"\"\n","    lens = [len(row[\"sentence\"]) for row in batch]\n","    bsz, max_seq_len = len(batch), max(lens)\n","\n","    # Initialize tensors\n","    mask_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n","    text_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n","\n","    # Fill in data\n","    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n","        text_tensor[i_batch, :length] = input_row[\"sentence\"]\n","        mask_tensor[i_batch, :length] = 1\n","\n","    # Extract other data features\n","    img_tensor = torch.stack([row[\"image\"] for row in batch])\n","    tgt_tensor = torch.stack([row[\"label\"] for row in batch])\n","    img_start_token = torch.stack([row[\"image_start_token\"] for row in batch])\n","    img_end_token = torch.stack([row[\"image_end_token\"] for row in batch])\n","\n","    return text_tensor, mask_tensor, img_tensor, img_start_token, img_end_token, tgt_tensor\n"],"metadata":{"id":"vuTRoEbtTj8b","executionInfo":{"status":"ok","timestamp":1692148973267,"user_tz":240,"elapsed":131,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/cs688project2/data/\""],"metadata":{"id":"lBqMMEPNb3hL","executionInfo":{"status":"ok","timestamp":1692148973267,"user_tz":240,"elapsed":3,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(path + 'final_cleaned_with_all_tags.csv')\n","df_train = df[:8500]\n","df_val = df[8500:9540]\n","df_test = df[9540:]"],"metadata":{"id":"044pAt-YbvWk","executionInfo":{"status":"ok","timestamp":1692148974234,"user_tz":240,"elapsed":969,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df_train.to_json('/content/drive/MyDrive/cs688project2/data/train_3.jsonl', orient='records', lines=True)\n","df_val.to_json('/content/drive/MyDrive/cs688project2/data/val_3.jsonl', orient='records', lines=True)"],"metadata":{"id":"1TdrljR0cdcN","executionInfo":{"status":"ok","timestamp":1692148974800,"user_tz":240,"elapsed":572,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def load_examples(tokenizer, evaluate=False):\n","    \"\"\"\n","    Load dataset examples from JSONL files.\n","\n","    Args:\n","    - tokenizer (Tokenizer): Tokenizer for text preprocessing.\n","    - evaluate (bool, optional): Whether to load validation data or training data. Default: False (load training data).\n","\n","    Returns:\n","    - JsonlDataset: Dataset containing loaded examples.\n","    \"\"\"\n","    # Determine the path based on whether it's for evaluation or training.\n","    path = os.path.join(data_dir, \"val_3.jsonl\" if evaluate else \"train_3.jsonl\")\n","    # Instantiate the dataset using the given path, tokenizer, transforms, and a pre-defined max sequence length.\n","    dataset = JsonlDataset(path, tokenizer, preprocess, max_seq_length - num_image_embeds - 2)\n","    return dataset\n","\n","\n","def save_checkpoint(save_path, model, valid_loss):\n","    \"\"\"\n","    Save the model's state along with its validation loss.\n","\n","    Args:\n","    - save_path (str): Path where the model should be saved.\n","    - model (nn.Module): Model to save.\n","    - valid_loss (float): Validation loss associated with the model.\n","\n","    Returns:\n","    - None\n","    \"\"\"\n","    if not save_path:\n","        return\n","\n","    # Define the state dictionary.\n","    state_dict = {\n","        'model_state_dict': model.state_dict(),\n","        'valid_loss': valid_loss\n","    }\n","\n","    # Save the model.\n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_checkpoint(load_path, model):\n","    \"\"\"\n","    Load a model's state from a checkpoint.\n","\n","    Args:\n","    - load_path (str): Path from where the model should be loaded.\n","    - model (nn.Module): Model to which the state should be loaded.\n","\n","    Returns:\n","    - float: The validation loss associated with the loaded model state.\n","    \"\"\"\n","    if not load_path:\n","        return\n","\n","    # Load the state dictionary.\n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","\n","    # Load the state into the model.\n","    model.load_state_dict(state_dict['model_state_dict'])\n","    return state_dict['valid_loss']\n"],"metadata":{"id":"iuZY9D4STm9f","executionInfo":{"status":"ok","timestamp":1692148998425,"user_tz":240,"elapsed":96,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Name of the pre-trained model\n","model_name = 'Hate-speech-CNERG/bert-base-uncased-hatexplain'\n","\n","# Load configuration for the transformer model. This includes settings specific to the model, like number of layers and hidden sizes.\n","transformer_config = AutoConfig.from_pretrained(model_name)\n","\n","# Load the pre-trained transformer model with the specified configuration\n","transformer = AutoModel.from_pretrained(model_name, config=transformer_config)\n","\n","# Create an instance of the ClipEncoder for multi-modal (image + text) embeddings\n","img_encoder = ClipEncoderMulti(num_image_embeds)\n","\n","# Initialize the tokenizer for the model. This will help in converting text into format suitable for model input.\n","tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n","\n","# Set configuration for the MMBT (Multi-Modal Bitransformers) model. It includes settings from transformer_config and additional parameters for multi-modality.\n","config = MMBTConfig(transformer_config, num_labels=num_labels, modal_hidden_size=image_features_size)\n","\n","# Initialize the MMBT model for classification tasks, integrating the transformer and image encoder.\n","model = MMBTForClassification(config, transformer, img_encoder)\n","\n","# Move the model to the specified device (e.g., GPU or CPU)\n","model.to(device);\n"],"metadata":{"id":"r1tH5mCKTsZ2","colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["e7ff675888ad4a7dad6d3c558aa35c91","4d25a4c3bb89446991a245cece00dc29","3dd4f893d94e4750b3f86cfb7bba104f","51ceffb74a8d4d368a26e2508b183529","1cdfc054b14b4dcc95e4c2f0247bca7e","9fba1342720d452981cd8b2f058d9390","f67668cafed344139051cea8931bca22","783148f971cd4df4812b2cdcb27d8c66","4877ed18980f422d8b49712ad4a0965a","6e132ce94cd949d298f18e0bcd250d05","e626a5b0065f497ba2ed712bc3db3fe9","5fe0c7eb82f1431bbeedffc5f84800a1","1743fdc522db4f6ea12791863cb902eb","bf7f0c550a8648b5872fba9117b601fb","57b2c4552b7343578ff3b687f8ec55c4","7ea9e0d239154c8b81082eb7c98b897f","47c9133bd03d4261907d5735ba1ea79a","c01a9af1e300468e967dffef2182d201","ca9aa5830bfa4c71b280d17b90254a27","087dd8a3f1614b7a8f4dc2d934429713","2ddfed45e5b8456891c456d4766c40cb","a00c0605d9f34aeca92972811fb94c82","673648f961534dd2ab5065e271f97c50","99e0c95baf6346578b8b93709980756e","d3522c75db0d438c91e3fe2c7796c340","ea5c525ec4b842899f029f416c9f0216","71ace7a6401946468a2e14708357a89f","5d9fdedbad1c48bdbf832f7464a36686","c274080ebac14e6598cc9efcc85c4d2a","f95ef1fd92414c1bb40e38ddbf60a536","ba9c6b7adbe24a76af36f24732d1225a","41672651f1e146fa873f7ce90dfe39c0","23109c733dac495ba2c24659061f6f5c","79660804e33444a7ba6a51f0296199f7","a58d5ccee07544f198e4bb6f4239c119","d832d63d6f574a6c98b4e7ff8b0c7d10","98a8e43be19542bfac4d05aa1a69a5bb","4a34fd44bd86490586921ec32d0c51b1","5f84f9ad4f0846b79006a1b526d474ec","d3851d224c614ccdbbbf88a60b7c35e8","983bf52376f24d78bdeda097b2c8ed68","c103f77640fb4e99ac84e1395b210b12","e7648af01ad0408a9a3473157a53658e","0d30947a8cbb409cb5c181f4887d4fd6","b514666c161f4d96b3bb4f3d245c2ad9","a17bdf8b675d4fc0b108099c860a16da","844da87cb5b54eb9a62b489486b3413c","97f760561e324760ab27ea84e35c79b1","53a60dba03584acfaab1b5d5de922fc1","ca2d4ccb27d942c7a012a804e6b02cdf","1d741267cc0347a6a81e812e1f0f17ee","e9014b842de742559986d05c50b4c931","1918c1a4e0b2470da7813743e088522d","d5b165c9ce674ee8b7aed68cdf4eb369","53d2a2f17c0c40a085789ba4a9873f3e"]},"executionInfo":{"status":"ok","timestamp":1692149099183,"user_tz":240,"elapsed":10238,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}},"outputId":"43b19e5b-1837-4ace-ba6d-524acdc8a464"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ff675888ad4a7dad6d3c558aa35c91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fe0c7eb82f1431bbeedffc5f84800a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"673648f961534dd2ab5065e271f97c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79660804e33444a7ba6a51f0296199f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b514666c161f4d96b3bb4f3d245c2ad9"}},"metadata":{}}]},{"cell_type":"code","source":["# Load training examples from the data source using a custom function; 'evaluate' flag indicates if it's for evaluation or not.\n","train_dataset = load_examples(tokenizer, evaluate=False)\n","\n","# Similarly, load evaluation examples. The 'evaluate' flag is set to True to differentiate it from the training dataset.\n","eval_dataset = load_examples(tokenizer, evaluate=True)\n","\n","# Create a sampler for the training dataset that selects data randomly. This helps in stochastic gradient descent optimization.\n","train_sampler = RandomSampler(train_dataset)\n","\n","# For the evaluation dataset, samples are drawn sequentially. This ensures we cover the entire dataset during evaluation.\n","eval_sampler = SequentialSampler(eval_dataset)\n","\n","# Initialize a DataLoader for the training dataset.\n","# DataLoader facilitates efficient loading of data in batches during training.\n","# - 'sampler' is used to specify the sampling strategy.\n","# - 'batch_size' determines the number of examples in each batch.\n","# - 'collate_fn' is a function to collate/batch the data samples into a batched format.\n","train_dataloader = DataLoader(\n","        train_dataset,\n","        sampler=train_sampler,\n","        batch_size=train_batch_size,\n","        collate_fn=collate_fn\n","    )\n","\n","# Similarly, initialize a DataLoader for the evaluation dataset.\n","eval_dataloader = DataLoader(\n","        eval_dataset,\n","        sampler=eval_sampler,\n","        batch_size=eval_batch_size,\n","        collate_fn=collate_fn\n","    )\n"],"metadata":{"id":"vth3vDVjTuCn","executionInfo":{"status":"ok","timestamp":1692149150439,"user_tz":240,"elapsed":191,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Prepare optimizer and its schedule (linear warmup and decay)\n","\n","# List of model parameters that shouldn't undergo decay.\n","# These often include bias terms and normalization layer weights as decaying them might harm model's training.\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","\n","# Set the default weight decay. Weight decay is a form of regularization to prevent overfitting.\n","weight_decay = 0.0005\n","\n","# Group model parameters based on whether they should undergo weight decay or not.\n","optimizer_grouped_parameters = [\n","        {\n","            # Parameters which should have weight decay applied\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": weight_decay,\n","        },\n","        {\n","            # Parameters which shouldn't have weight decay applied\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","\n","# Calculate the total number of training steps. This is used for scheduler.\n","# gradient_accumulation_steps refers to the number of steps to accumulate gradients before optimizing.\n","t_total = (len(train_dataloader) // gradient_accumulation_steps) * num_train_epochs\n","\n","# Define warmup steps as a fraction of total training steps.\n","# Warmup is a period where the learning rate is gradually increased from a very small value to the set value.\n","warmup_steps = t_total // 10\n","\n","# Initialize the MADGRAD optimizer with the specified parameters and learning rate.\n","optimizer = MADGRAD(optimizer_grouped_parameters, lr=2e-4)\n","\n","# Set up the learning rate scheduler with linear warmup at the beginning and decay afterwards.\n","scheduler = get_linear_schedule_with_warmup(\n","        optimizer, warmup_steps, t_total\n","    )\n","\n","# Define the loss function for training.\n","# BCEWithLogitsLoss combines a Sigmoid layer and the BCELoss (Binary Cross-Entropy loss) in one single class.\n","criterion = nn.BCEWithLogitsLoss()\n"],"metadata":{"id":"lb74MvPaWf18","executionInfo":{"status":"ok","timestamp":1692149211566,"user_tz":240,"elapsed":87,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, tokenizer, criterion, dataloader, threshold=0.5):\n","    \"\"\"\n","    Evaluate the model on a given dataloader.\n","\n","    Parameters:\n","    - model: The model to be evaluated.\n","    - tokenizer: Tokenizer for text preprocessing.\n","    - criterion: The loss function.\n","    - dataloader: DataLoader for evaluation data.\n","    - threshold: Threshold for classification, defaults to 0.5.\n","\n","    Returns:\n","    - result: Dictionary containing evaluation metrics and other details.\n","    \"\"\"\n","\n","    # Initialize variables for evaluation metrics and predictions.\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    preds = []\n","    proba = []\n","    out_label_ids = []\n","\n","    # Set the model in evaluation mode.\n","    model.eval()\n","\n","    # Loop over batches from the dataloader.\n","    for batch in dataloader:\n","        # Move batch tensors to the same device as the model.\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # Disable gradient calculations, as they aren't needed for evaluation.\n","        with torch.no_grad():\n","            labels = batch[5]\n","            inputs = {\n","                \"input_ids\": batch[0],\n","                \"input_modal\": batch[2],\n","                \"attention_mask\": batch[1],\n","                \"modal_start_tokens\": batch[3],\n","                \"modal_end_tokens\": batch[4],\n","                \"return_dict\": False\n","            }\n","\n","            # Obtain model outputs.\n","            outputs = model(**inputs)\n","            logits = outputs[0]  # Extract logits from outputs.\n","\n","            # Calculate loss for the current batch.\n","            tmp_eval_loss = criterion(logits, labels)\n","            eval_loss += tmp_eval_loss.mean().item()\n","\n","        nb_eval_steps += 1\n","\n","        # Convert logits to probabilities and predictions.\n","        batch_proba = torch.sigmoid(logits).detach().cpu().numpy()\n","        batch_preds = batch_proba > threshold\n","        batch_labels = labels.detach().cpu().numpy()\n","\n","        # Append batch results to lists.\n","        preds.extend(batch_preds)\n","        proba.extend(batch_proba)\n","        out_label_ids.extend(batch_labels)\n","\n","    # Calculate the average loss over all batches.\n","    eval_loss = eval_loss / nb_eval_steps\n","\n","    # Create a result dictionary with evaluation metrics.\n","    result = {\n","        \"loss\": eval_loss,\n","        \"accuracy\": accuracy_score(out_label_ids, preds),\n","        \"AUC\": roc_auc_score(out_label_ids, proba),\n","        \"micro_f1\": f1_score(out_label_ids, preds, average=\"micro\"),\n","        \"prediction\": np.array(preds),\n","        \"labels\": np.array(out_label_ids),\n","        \"proba\": np.array(proba)\n","    }\n","\n","    return result\n"],"metadata":{"id":"TbEZoFcjaXNP","executionInfo":{"status":"ok","timestamp":1692149294251,"user_tz":240,"elapsed":141,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Initialization of variables for training metrics, model state tracking and checkpointing.\n","optimizer_step = 0\n","global_step = 0\n","train_step = 0\n","tr_loss, logging_loss = 0.0, 0.0\n","best_valid_auc = 0.75\n","global_steps_list = []\n","train_loss_list = []\n","val_loss_list = []\n","val_acc_list = []\n","val_auc_list = []\n","eval_every = len(train_dataloader) // 7  # Frequency of evaluation during training.\n","running_loss = 0\n","checkpoint_directory = \"/content/drive/MyDrive/cs688project2/data/models/\"\n","\n","# Zero out model gradients at the start.\n","model.zero_grad()\n","\n","# Training loop for multiple epochs.\n","for epoch in range(num_train_epochs):\n","    print(f\"Epoch {epoch + 1} of {num_train_epochs}\")\n","\n","    # Tracking predictions and true labels for metrics calculation.\n","    whole_y_pred = np.array([])\n","    whole_y_t = np.array([])\n","\n","    # Loop through each batch from the training dataloader.\n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","        # Set model to training mode.\n","        model.train()\n","\n","        # Transfer batch to device.\n","        batch = tuple(t.to(device) for t in batch)\n","        labels = batch[5]\n","\n","        # Prepare inputs for the model.\n","        inputs = {\n","            \"input_ids\": batch[0],\n","            \"input_modal\": batch[2],\n","            \"attention_mask\": batch[1],\n","            \"modal_start_tokens\": batch[3],\n","            \"modal_end_tokens\": batch[4],\n","            \"return_dict\": False\n","        }\n","\n","        # Get model outputs.\n","        outputs = model(**inputs)\n","        logits = outputs[0]\n","        loss = criterion(logits, labels)\n","\n","        # Handle gradient accumulation if set.\n","        if gradient_accumulation_steps > 1:\n","            loss = loss / gradient_accumulation_steps\n","\n","        loss.backward()\n","\n","        # Update training loss trackers.\n","        tr_loss += loss.item()\n","        running_loss += loss.item()\n","        global_step += 1\n","\n","        # Update model parameters if gradient accumulation is fulfilled.\n","        if (step + 1) % gradient_accumulation_steps == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","            optimizer.step()\n","            scheduler.step()  # Update learning rate schedule\n","            optimizer_step += 1\n","            optimizer.zero_grad()\n","\n","        # Evaluate model periodically.\n","        if (step + 1) % eval_every == 0:\n","            average_train_loss = running_loss / eval_every\n","            train_loss_list.append(average_train_loss)\n","            global_steps_list.append(global_step)\n","            running_loss = 0.0\n","\n","            # Validate the model.\n","            val_result = evaluate(model, tokenizer, criterion, eval_dataloader)\n","            val_loss_list.append(val_result['loss'])\n","            val_acc_list.append(val_result['accuracy'])\n","            val_auc_list.append(val_result['AUC'])\n","\n","            # Save model checkpoint if AUC has improved.\n","            if val_result['AUC'] > best_valid_auc:\n","                best_valid_auc = val_result['AUC']\n","                model_path = f'{checkpoint_directory}/model-embs{num_image_embeds}-seq{max_seq_length}-auc{best_valid_auc:.3f}-loss{val_result[\"loss\"]:.3f}-acc{val_result[\"accuracy\"]:.3f}.pt'\n","                print(f\"AUC improved, so saving this model to {model_path}\")\n","                save_checkpoint(model_path, model, val_result['loss'])\n","\n","            # Log training and validation metrics.\n","            print(f\"Train loss: {average_train_loss:.4f}, Val loss: {val_result['loss']:.4f}, Val accuracy: {val_result['accuracy']:.4f}, AUC: {val_result['AUC']:.4f}\")\n","\n","    print('\\n')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f85be8e2c4304d8cbbf41846e7404f4a","ca82ce8696c14c3d878c93f5c63a1c6d","4cbd0175603346b9add2b86c21aad32f","093e6fd0bfc64eaea1e50e1eded7a1c8","dca6a3a1abbb46d1a36ead6691e35b3a","666e3f8e2dbd4eb182ed42a1c63e6e1f","f8fd3de03c2541a1a8cba39aef73738e","24602f546f4d4369a67f19ad96b19332","5b7b5b4ad89d437bb88c0b672d1e7979","b2f9e8ddbfe54a7f8decd27de8c9cc35","bf0f044922c84955a0476b6af3a454ae","e11fa0e616754fd7bf286b2e9135e9a8","78bc4aaf7e2f4e16a5c2a828f86bd65c","fb68a3c6e7364cf3bb5f80be2e442774","b8e7078105774f379ea1351e2636195c","ccf92f30de104ea9943e9ae7f549b517","3f64c5d29eec4bf58e0cb6085f2ce7bd","483162e128ce4475a0f767f5b5ec19c4","ac455917be6a4045a2b08b8a4519e8b9","9fced1b06fd24654b7c4adab1f0ec9b5","e428b47c5db1428a9e7e13b6f3820a1b","c81f914c711f4cafafc392838c14223d"]},"id":"Yc6uisbYaZS-","executionInfo":{"status":"error","timestamp":1692152885734,"user_tz":240,"elapsed":2757349,"user":{"displayName":"Sandeep Yerra","userId":"11670177343119609431"}},"outputId":"13a12bf5-ed4b-424f-a2b6-2e64a911b6d1"},"execution_count":16,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1 of 5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f85be8e2c4304d8cbbf41846e7404f4a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/532 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss: 0.0327, Val loss: 0.7610, Val accuracy: 0.5000, AUC: 0.5270\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0320, Val loss: 0.7574, Val accuracy: 0.5058, AUC: 0.5796\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0307, Val loss: 0.7283, Val accuracy: 0.5654, AUC: 0.6139\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0282, Val loss: 0.8009, Val accuracy: 0.5721, AUC: 0.6325\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0283, Val loss: 0.7013, Val accuracy: 0.5894, AUC: 0.6724\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0277, Val loss: 0.7702, Val accuracy: 0.5837, AUC: 0.6911\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0266, Val loss: 0.7853, Val accuracy: 0.5779, AUC: 0.7017\n","\n","\n","Epoch 2 of 5\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/532 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11fa0e616754fd7bf286b2e9135e9a8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.0241, Val loss: 0.6834, Val accuracy: 0.6404, AUC: 0.7070\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f96d43e93617>:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n","<ipython-input-5-f96d43e93617>:60: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  im = im.resize(new_size, Image.ANTIALIAS)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-74baede2c358>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Validate the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mval_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-c94b643f70c9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, tokenizer, criterion, dataloader, threshold)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Loop over batches from the dataloader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Move batch tensors to the same device as the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-9a6800678915>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0msliced_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msliced_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msliced_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_pad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_encoder_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-9a6800678915>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0msliced_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msliced_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msliced_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_pad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_encoder_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}